{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZLhR1MLWmXNhPf59XHggd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuzetao/vue/blob/main/%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%96%B9%E7%A8%8B%E4%BC%98%E5%8C%96%E7%89%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szuUitb9Az22",
        "outputId": "02e2f13a-f909-459e-9572-d06bb8578fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "第0次迭代损失=-24.589231491088867\n",
            "第100次迭代损失=-1167.954345703125\n",
            "第200次迭代损失=-1390.734619140625\n",
            "第300次迭代损失=-1786.4862060546875\n",
            "第400次迭代损失=-1558.591552734375\n",
            "第500次迭代损失=-1692.933349609375\n",
            "第600次迭代损失=-1850.6126708984375\n",
            "第700次迭代损失=-1575.14453125\n",
            "第800次迭代损失=-1706.520263671875\n",
            "第900次迭代损失=-1629.36962890625\n",
            "第1000次迭代损失=-1774.9539794921875\n",
            "第1100次迭代损失=-1883.56201171875\n",
            "第1200次迭代损失=-1948.166015625\n",
            "第1300次迭代损失=-1888.4742431640625\n",
            "第1400次迭代损失=-1733.1900634765625\n",
            "第1500次迭代损失=-1814.25341796875\n",
            "第1600次迭代损失=-1745.00830078125\n",
            "第1700次迭代损失=-1766.095947265625\n",
            "第1800次迭代损失=-1780.9029541015625\n",
            "第1900次迭代损失=-1759.040283203125\n",
            "第2000次迭代损失=-1902.2197265625\n",
            "第2100次迭代损失=-1591.1470947265625\n",
            "第2200次迭代损失=-1842.8150634765625\n",
            "第2300次迭代损失=-1776.416259765625\n",
            "第2400次迭代损失=-1662.2872314453125\n",
            "第2500次迭代损失=-1827.504638671875\n",
            "第2600次迭代损失=-1683.772216796875\n",
            "第2700次迭代损失=-1847.170654296875\n",
            "第2800次迭代损失=-1756.751953125\n",
            "第2900次迭代损失=-1799.880859375\n",
            "第3000次迭代损失=-1882.1102294921875\n",
            "第3100次迭代损失=-1899.0450439453125\n",
            "第3200次迭代损失=-1586.619873046875\n",
            "第3300次迭代损失=-1855.00830078125\n",
            "第3400次迭代损失=-1747.649658203125\n",
            "第3500次迭代损失=-1688.194580078125\n",
            "第3600次迭代损失=-1783.239013671875\n",
            "第3700次迭代损失=-1687.3690185546875\n",
            "第3800次迭代损失=-1741.098388671875\n",
            "第3900次迭代损失=-1803.46044921875\n",
            "第4000次迭代损失=-1657.5498046875\n",
            "第4100次迭代损失=-1774.977294921875\n",
            "第4200次迭代损失=-1635.845458984375\n",
            "第4300次迭代损失=-1672.47607421875\n",
            "第4400次迭代损失=-1788.7969970703125\n",
            "第4500次迭代损失=-1859.1976318359375\n",
            "第4600次迭代损失=-1618.17822265625\n",
            "第4700次迭代损失=-1749.924072265625\n",
            "第4800次迭代损失=-1817.2294921875\n",
            "第4900次迭代损失=-1684.342529296875\n",
            "第5000次迭代损失=-1663.8150634765625\n",
            "第5100次迭代损失=-1900.429931640625\n",
            "第5200次迭代损失=-1944.16845703125\n",
            "第5300次迭代损失=-1627.4718017578125\n",
            "第5400次迭代损失=-1737.7103271484375\n",
            "第5500次迭代损失=-1744.879150390625\n",
            "第5600次迭代损失=-1682.793701171875\n",
            "第5700次迭代损失=-1853.30810546875\n",
            "第5800次迭代损失=-1662.7435302734375\n",
            "第5900次迭代损失=-1831.81005859375\n",
            "第6000次迭代损失=-1805.618896484375\n",
            "第6100次迭代损失=-1742.2215576171875\n",
            "第6200次迭代损失=-1717.4088134765625\n",
            "第6300次迭代损失=-1789.0322265625\n",
            "第6400次迭代损失=-1643.2001953125\n",
            "第6500次迭代损失=-1582.2061767578125\n",
            "第6600次迭代损失=-1772.2138671875\n",
            "第6700次迭代损失=-1692.7835693359375\n",
            "第6800次迭代损失=-1802.018310546875\n",
            "第6900次迭代损失=-1763.33349609375\n",
            "第7000次迭代损失=-1779.367919921875\n",
            "第7100次迭代损失=-1822.66748046875\n",
            "第7200次迭代损失=-1778.7435302734375\n",
            "第7300次迭代损失=-1794.547607421875\n",
            "第7400次迭代损失=-1642.441162109375\n",
            "第7500次迭代损失=-1630.00830078125\n",
            "第7600次迭代损失=-1631.158203125\n",
            "第7700次迭代损失=-1850.9481201171875\n",
            "第7800次迭代损失=-1867.43505859375\n",
            "第7900次迭代损失=-1789.41796875\n",
            "第8000次迭代损失=-1612.501220703125\n",
            "第8100次迭代损失=-1908.458984375\n",
            "第8200次迭代损失=-1890.0203857421875\n",
            "第8300次迭代损失=-1715.412353515625\n",
            "第8400次迭代损失=-1584.004150390625\n",
            "第8500次迭代损失=-1695.11376953125\n",
            "第8600次迭代损失=-1697.834228515625\n",
            "第8700次迭代损失=-1736.177490234375\n",
            "第8800次迭代损失=-1940.855712890625\n",
            "第8900次迭代损失=-1635.364990234375\n",
            "第9000次迭代损失=-1717.08349609375\n",
            "第9100次迭代损失=-1619.344482421875\n",
            "第9200次迭代损失=-1530.0850830078125\n",
            "第9300次迭代损失=-1750.3363037109375\n",
            "第9400次迭代损失=-1723.41796875\n",
            "第9500次迭代损失=-1938.961669921875\n",
            "第9600次迭代损失=-1735.617919921875\n",
            "第9700次迭代损失=-1969.6856689453125\n",
            "第9800次迭代损失=-1640.689453125\n",
            "第9900次迭代损失=-1694.7725830078125\n",
            "第10000次迭代损失=-1712.27734375\n",
            "第10100次迭代损失=-1909.82958984375\n",
            "第10200次迭代损失=-1777.69287109375\n",
            "第10300次迭代损失=-1560.232177734375\n",
            "第10400次迭代损失=-1749.065673828125\n",
            "第10500次迭代损失=-1815.13671875\n",
            "第10600次迭代损失=-1817.8052978515625\n",
            "第10700次迭代损失=-1813.565673828125\n",
            "第10800次迭代损失=-1751.6109619140625\n",
            "第10900次迭代损失=-1820.321044921875\n",
            "第11000次迭代损失=-1543.5123291015625\n",
            "第11100次迭代损失=-1810.8421630859375\n",
            "第11200次迭代损失=-1650.440185546875\n",
            "第11300次迭代损失=-1765.29345703125\n",
            "第11400次迭代损失=-1949.474609375\n",
            "第11500次迭代损失=-1755.309814453125\n",
            "第11600次迭代损失=-1732.7135009765625\n",
            "第11700次迭代损失=-1897.491943359375\n",
            "第11800次迭代损失=-1677.68212890625\n",
            "第11900次迭代损失=-1706.885986328125\n",
            "第12000次迭代损失=-1669.4599609375\n",
            "第12100次迭代损失=-1594.68798828125\n",
            "第12200次迭代损失=-1536.51025390625\n",
            "第12300次迭代损失=-2105.87841796875\n",
            "第12400次迭代损失=-1553.60791015625\n",
            "第12500次迭代损失=-1604.4248046875\n",
            "第12600次迭代损失=-1964.942138671875\n",
            "第12700次迭代损失=-1631.271728515625\n",
            "第12800次迭代损失=-1590.1199951171875\n",
            "第12900次迭代损失=-1841.563232421875\n",
            "第13000次迭代损失=-1823.929443359375\n",
            "第13100次迭代损失=-1640.415283203125\n",
            "第13200次迭代损失=-1699.608642578125\n",
            "第13300次迭代损失=-1931.08544921875\n",
            "第13400次迭代损失=-1808.89599609375\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import Linear, ReLU, Sequential\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "\n",
        "net= Sequential(\n",
        "    # Linear(3,8),\n",
        "    # ReLU(),\n",
        "    # Linear(8,1024),\n",
        "    # ReLU(),\n",
        "    # Linear(1024,4096),\n",
        "    # ReLU(),\n",
        "    # Linear(4096,8192),\n",
        "    # ReLU(),\n",
        "    # Linear(8192,16384),\n",
        "    # ReLU(),\n",
        "    # Linear(16384,32768),\n",
        "    # ReLU(),\n",
        "    # Linear(32768,16384),\n",
        "    # ReLU(),\n",
        "    # Linear(16384,8192),\n",
        "    # ReLU(),\n",
        "    # Linear(8192,4096),\n",
        "    # ReLU(),\n",
        "    # Linear(4096,2048),\n",
        "    # ReLU(),\n",
        "    # Linear(2048,1024),\n",
        "    # ReLU(),\n",
        "    # Linear(1024,8),\n",
        "    # ReLU(),\n",
        "    #15gb cuda over\n",
        "\n",
        "\n",
        "    Linear(3,8),\n",
        "    ReLU(),\n",
        "    Linear(8,16),\n",
        "    ReLU(),\n",
        "    Linear(16,32),\n",
        "    ReLU(),\n",
        "    Linear(32,16),\n",
        "    ReLU(),\n",
        "    Linear(16,8),\n",
        "    ReLU(),\n",
        "    Linear(8,1),\n",
        "    #15gb cuda vram ok  max\n",
        "\n",
        "\n",
        ")\n",
        "def g(x,y):\n",
        "    x0,x1,x2=x[:,0]**0,x[:,1]**1,x[:,2]**2\n",
        "    y0=y[:,0]\n",
        "    return (x0+x1+x2)*y0-y0*y0-x0*x1*x2\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer =Adam(net.parameters())\n",
        "for step in range(30000):\n",
        "    optimizer.zero_grad()\n",
        "    x=torch.randn(1000,3).cuda()\n",
        "    net.cuda()\n",
        "    y=net(x)\n",
        "    outputs=g(x,y).cuda()\n",
        "    loss=-torch.sum(outputs)\n",
        "    #loss=loss-torch.sum(outputs)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if step % 100 ==0:\n",
        "        print('第{}次迭代损失={}'.format(step,loss))\n",
        "\n",
        "\n",
        "def test():\n",
        "  x_test =torch.randn(2,3).cuda()\n",
        "  #x_test =torch.ones(2,3).cuda()\n",
        "  #print('测试输入:{}'.format(x_test))\n",
        "  net.cuda()\n",
        "  y_test=net(x_test)\n",
        "  print('人工神经网络计算结果:{}'.format(y_test))\n",
        "  print('g的值:{}'.format(g(x_test,y_test)))\n",
        "  print('')\n",
        "  yref_test=argmax_g(x_test)\n",
        "  print('理论最优值:{}'.format(yref_test))\n",
        "  print('g的值:{}'.format(g(x_test,yref_test)))\n",
        "  print('')\n",
        "\n",
        "\n",
        "def argmax_g(x):\n",
        "  x0,x1,x2=x[:,0]**0,x[:,1]**1,x[:,2]**2\n",
        "  return 0.5*(x0+x1+x2)[:,None]\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "dYP44ERdKWw3",
        "outputId": "ac268ee9-3322-41eb-98f1-c3ca0fb01e37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4907366c395a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFTfkMFKGf7Q",
        "outputId": "253a1ed7-ece6-4ec5-ec26-4caecdb01655"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 11 02:43:30 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    26W /  70W |  15019MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}